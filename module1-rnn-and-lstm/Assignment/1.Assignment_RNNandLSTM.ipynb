{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "1.Assignment_RNNandLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8elqlLyi11ub",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "outputId": "d02bc8f9-8ab4-4ec8-d6a6-10716dfc3b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "titles = 'https://raw.githubusercontent.com/CVanchieri/DS-Unit-4-Sprint-3-Deep-Learning/master/module1-rnn-and-lstm/articles/titles.csv'\n",
        "sonnets = 'https://raw.githubusercontent.com/CVanchieri/DS-Unit-4-Sprint-3-Deep-Learning/master/module1-rnn-and-lstm/articles/sonnets.csv'\n",
        "dft = pd.read_csv(titles, header=None)\n",
        "dfs = pd.read_csv(sonnets, sep = '\\n', header=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtKQgQMaI6Lv",
        "colab_type": "code",
        "outputId": "83a5f5f9-09fc-4605-baa4-27394b961688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# show the dataframe shape.\n",
        "print(dft.shape)\n",
        "# show the dataframe with headers.\n",
        "dft.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(44, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE SONNETS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ALL’S WELL THAT ENDS WELL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     0\n",
              "0                          THE SONNETS\n",
              "1            ALL’S WELL THAT ENDS WELL\n",
              "2  THE TRAGEDY OF ANTONY AND CLEOPATRA\n",
              "3                       AS YOU LIKE IT\n",
              "4                 THE COMEDY OF ERRORS"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7_162JBJdOO",
        "colab_type": "code",
        "outputId": "6d3dedd9-593d-41f1-8ee6-619c7ac23ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# show the dataframe shape.\n",
        "print(dfs.shape)\n",
        "# show the dataframe with headers.\n",
        "dfs.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2309, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From fairest creatures we desire increase,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>That thereby beauty’s rose might never die,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>But as the riper should by time decease,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>His tender heir might bear his memory:</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             0\n",
              "0                                            1\n",
              "1   From fairest creatures we desire increase,\n",
              "2  That thereby beauty’s rose might never die,\n",
              "3     But as the riper should by time decease,\n",
              "4       His tender heir might bear his memory:"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuCQ5ctlPngE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfs = dfs[~dfs[0].str.contains(r'\\d')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHjnjX9pPUHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode data as chars.\n",
        "text = \" \".join(dfs[0].tolist())\n",
        "chars = list(set(text))\n",
        "\n",
        "char_int = {c:i for i,c in enumerate(chars)}\n",
        "int_char = {i:c for i,c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bmn4Et2Qwr4",
        "colab_type": "code",
        "outputId": "41ac9333-43db-4172-faf8-cdad9814ee36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# show the length of the chars.\n",
        "len(chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7WzxiYgQwuL",
        "colab_type": "code",
        "outputId": "73a37a34-4d9c-4750-bfff-8ed37bbf589f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create the squence data.\n",
        "# The lists are: encoded (chars encoded as integers)\n",
        "#                sequences (40 chars per entry)\n",
        "#                next_chars ()\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # each element is 40 chars long.\n",
        "next_chars = [] # one element for each sequence for prediction.\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_chars.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences', len(sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences 18848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzKlV3uhQwy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify x & y - 3D matrix.\n",
        "\n",
        "# initialize arrays with False.\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_chars[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8t_t0GKwBfH",
        "colab_type": "text"
      },
      "source": [
        "### base model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjUbUEtbpsVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.core import Dropout\n",
        "\n",
        "# create baseline model.\n",
        "def create_model():\n",
        "    # set the sequential model.\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(maxlen, len(chars)))) #input shape of a singular observ.\n",
        "    model.add(Dense(len(chars), activation='softmax'))\n",
        "    # compile the model.\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR3bF7rOunpw",
        "colab_type": "code",
        "outputId": "53554356-a4f8-4a2c-c898-027b35a98f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# set the model.\n",
        "model = create_model()\n",
        "# fit the model with parameters.\n",
        "model.fit(x, y, batch_size=20, epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18848 samples\n",
            "Epoch 1/2\n",
            "18848/18848 [==============================] - 84s 4ms/sample - loss: 2.8087 - acc: 0.2458\n",
            "Epoch 2/2\n",
            "18848/18848 [==============================] - 84s 4ms/sample - loss: 2.3405 - acc: 0.3446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd4b88badd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCYEy5mxxeIm",
        "colab_type": "text"
      },
      "source": [
        "### Batch Size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cML0NxD0sRTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports.\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# create the model.\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(maxlen, len(chars)))) #input shape of a singular observ.\n",
        "    model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "    # compile the model.\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f920iq_owjJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the model with kerasclassifier.\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ENDcsKwr4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the parameters for batch size.\n",
        "param_grid = {'batch_size': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
        "              }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCpeVTmUwkuR",
        "colab_type": "code",
        "outputId": "9e259d3e-77d8-4342-a11b-8d1e180831e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# set the gridsearch.\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(x, y)\n",
        "# show the results.\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.3395580530166626 using {'batch_size': 5}\n",
            "Means: 0.3395580530166626, Stdev: 0.008818184414304311 with: {'batch_size': 5}\n",
            "Means: 0.31663904786109925, Stdev: 0.006072138419425553 with: {'batch_size': 10}\n",
            "Means: 0.3111734390258789, Stdev: 0.007242021112283264 with: {'batch_size': 15}\n",
            "Means: 0.2996607780456543, Stdev: 0.007364043353493179 with: {'batch_size': 20}\n",
            "Means: 0.2855479121208191, Stdev: 0.011956522187677952 with: {'batch_size': 25}\n",
            "Means: 0.27233617305755614, Stdev: 0.008114202905722113 with: {'batch_size': 30}\n",
            "Means: 0.2667655348777771, Stdev: 0.004188886590738569 with: {'batch_size': 35}\n",
            "Means: 0.2366294026374817, Stdev: 0.030215467802852638 with: {'batch_size': 40}\n",
            "Means: 0.19238219559192657, Stdev: 0.009351837686857923 with: {'batch_size': 45}\n",
            "Means: 0.20431989729404448, Stdev: 0.01648868863783165 with: {'batch_size': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5boJ7Wvuyhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports.\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# create the model.\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(maxlen, len(chars)))) #input shape of a singular observ.\n",
        "    #model.add(Dropout(0.2))\n",
        "    model.add(Dense(len(chars), activation='relu'))\n",
        "    #model.add(Dropout(0.2))\n",
        "    model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "    #optimizer = Adam(lr=0.01)\n",
        "\n",
        "    # compile the model.\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLowIGnxGhZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the model with kerasclassifier.\n",
        "model = KerasClassifier(build_fn=create_model, batch_size=5, epochs=10, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3spwwCkpsj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the gridsearch.\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(x, y)\n",
        "# show the results.\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9focQzeRBlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create sample function.\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyFNGF-VRDSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create test function.\n",
        "def test(c_length):\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(c_length):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, 0.5)\n",
        "        next_char = int_char[next_index]\n",
        "\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "char_length = 400"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0pjU4_0RFPp",
        "colab_type": "code",
        "outputId": "c9c2d811-60d6-48a1-ce31-00c1bd32dedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# fit the model with parameters.\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18848 samples\n",
            "Epoch 1/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.9365\n",
            "Epoch 2/20\n",
            "18848/18848 [==============================] - 23s 1ms/sample - loss: 1.9187\n",
            "Epoch 3/20\n",
            "18848/18848 [==============================] - 23s 1ms/sample - loss: 1.9024\n",
            "Epoch 4/20\n",
            "18848/18848 [==============================] - 23s 1ms/sample - loss: 1.8865\n",
            "Epoch 5/20\n",
            "18848/18848 [==============================] - 23s 1ms/sample - loss: 1.8734\n",
            "Epoch 6/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.8580\n",
            "Epoch 7/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.8450\n",
            "Epoch 8/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.8289\n",
            "Epoch 9/20\n",
            "18848/18848 [==============================] - 23s 1ms/sample - loss: 1.8165\n",
            "Epoch 10/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.8037\n",
            "Epoch 11/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.7953\n",
            "Epoch 12/20\n",
            "18848/18848 [==============================] - 23s 1ms/sample - loss: 1.7821\n",
            "Epoch 13/20\n",
            "18848/18848 [==============================] - 23s 1ms/sample - loss: 1.7672\n",
            "Epoch 14/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.7554\n",
            "Epoch 15/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.7435\n",
            "Epoch 16/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.7287\n",
            "Epoch 17/20\n",
            "18848/18848 [==============================] - 24s 1ms/sample - loss: 1.7157\n",
            "Epoch 18/20\n",
            "18848/18848 [==============================] - 23s 1ms/sample - loss: 1.7059\n",
            "Epoch 19/20\n",
            "18848/18848 [==============================] - 25s 1ms/sample - loss: 1.6933\n",
            "Epoch 20/20\n",
            "18848/18848 [==============================] - 23s 1ms/sample - loss: 1.6812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd4c0054a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCUDfNnWRLbT",
        "colab_type": "code",
        "outputId": "58a86a90-3a1d-45e9-9309-aeafd835bc13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# use the text function on the char_length, gives test output.\n",
        "test(char_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Generating with seed: \"eed outbraves his dignity:   For sweetes\"\n",
            "eed outbraves his dignity:   For sweetes goud thou blauty dost my desthed thee blown, And pairt and have be to me the thear enes, And loves not loves whee sheal of thy praie, Mand and love of ance me for mine where with me to me, And arl heaven the preas,   Thou bether with love sighe with por bet, And sond hand I love not head your seake. To ene hat sepe sove more a to me beate, And more sweak come and shand not love eress for, Ere so \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}